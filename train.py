import torch
import os
from ultralytics import YOLO
import shutil
import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"

def check_disk_space(drive):
    total, used, free = shutil.disk_usage(drive)
    return free / (1024 ** 3)  # Dung l∆∞·ª£ng tr·ªëng (GB)

def check_environment():
    print("üîç Checking environment...")
    if torch.cuda.is_available():
        print(f"‚úÖ GPU: {torch.cuda.get_device_name(0)}")
    else:
        print("‚ö†Ô∏è No GPU. Using CPU (slow).")
    
    c_free = check_disk_space("C:\\")
    d_free = check_disk_space("D:\\")
    print(f"üíæ Drive C: {c_free:.2f} GB free")
    print(f"üíæ Drive D: {d_free:.2f} GB free")
    if c_free < 1:
        print("üö® Warning: Drive C is low (<1GB). Free up space or move swap file to D.")
    if d_free < 10:
        print("üö® Warning: Drive D is low (<10GB). Dataset and logs may fill it up.")

def train_model():
    # 1. KI·ªÇM TRA M√îI TR∆Ø·ªúNG
    # =================================
    check_disk_space("C:\\")  # Ki·ªÉm tra dung l∆∞·ª£ng ·ªï C:
    check_environment()  # G·ªçi h√†m ki·ªÉm tra m√¥i tr∆∞·ªùng v√† dung l∆∞·ª£ng ·ªï
    # Ki·ªÉm tra xem c√≥ GPU (nh∆∞ card NVIDIA) ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô hu·∫•n luy·ªán kh√¥ng.
    if torch.cuda.is_available():
        print("‚úÖ GPU is available! We will use it for training.")
        print(f"Device: {torch.cuda.get_device_name(0)}")
    else:
        print("‚ö†Ô∏è GPU is not available. Training will run on CPU, which might be very slow.")
        print("   If you are on Kaggle/Colab, make sure to enable the GPU accelerator.")


    # 2. C√ÅC THAM S·ªê HU·∫§N LUY·ªÜN
    # =================================
    # B·∫°n c√≥ th·ªÉ thay ƒë·ªïi c√°c gi√° tr·ªã n√†y ƒë·ªÉ th·ª≠ nghi·ªám.
    PRETRAINED_MODEL = 'yolov8n.pt'
    DATA_CONFIG = 'data.yaml'
    EPOCHS = 100
    IMAGE_SIZE = 640  # Gi·∫£m t·ª´ 640 ƒë·ªÉ ti·∫øt ki·ªám b·ªô nh·ªõ GPU
    BATCH_SIZE = 8    # Gi·∫£m t·ª´ 8 ƒë·ªÉ tr√°nh CUDA out of memory
    WORKERS = 4       # T·∫Øt multiprocessing ho·∫∑c ƒë·ªÉ l√† 2 ƒë·∫øn 4 ƒë·ªÉ gi·∫£m l·ªói shared file mapping


    # 3. HU·∫§N LUY·ªÜN M√î H√åNH
    # =================================
    # Ghi ch√∫: ƒê·ªÉ chuy·ªÉn sang notebook, b·∫°n ch·ªâ c·∫ßn copy ph·∫ßn code n√†y v√†o m·ªôt cell.
    print("\\nüöÄ Starting training...")
    try:
        # T·∫£i m·ªôt m√¥ h√¨nh YOLOv8 ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán tr∆∞·ªõc (pretrained).
        model = YOLO(PRETRAINED_MODEL)

        # B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh tr√™n dataset c·ªßa b·∫°n.
        # K·∫øt qu·∫£ s·∫Ω ƒë∆∞·ª£c l∆∞u trong th∆∞ m·ª•c `runs/detect/train/`
        results = model.train(
            data=DATA_CONFIG,
            epochs=EPOCHS,
            imgsz=IMAGE_SIZE,
            batch=BATCH_SIZE,
            workers=WORKERS,
            name='yolov8_traffic_sign_training', # T√™n th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£
            resume=False # Hu·∫•n luy·ªán ti·∫øp t·ª´ l·∫ßn ch·∫°y tr∆∞·ªõc
        )
        print("‚úÖ Training completed successfully!")
        
        # L·∫•y ƒë∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c k·∫øt qu·∫£ m·ªõi nh·∫•t
        latest_run_dir = max([os.path.join('runs/detect', d) for d in os.listdir('runs/detect') if os.path.isdir(os.path.join('runs/detect', d))], key=os.path.getmtime)
        weights_path = os.path.join(latest_run_dir, 'weights/best.pt')
        print(f"üëâ Best model weights saved at: {weights_path}")
        return weights_path

    except Exception as e:
        print(f"‚ùå An error occurred during training: {e}")
        return None


def run_inference(weights_path):
    # 4. CH·∫†Y NH·∫¨N DI·ªÜN (INFERENCE)
    # =================================
    # Sau khi hu·∫•n luy·ªán, b·∫°n c√≥ th·ªÉ d√πng ƒëo·∫°n code d∆∞·ªõi ƒë√¢y ƒë·ªÉ nh·∫≠n di·ªán tr√™n ·∫£nh m·ªõi.
    if not weights_path:
        print("\\n‚è© Skipping inference because training did not complete successfully.")
        return

    print("\\nüîé Running inference on a sample image...")
    try:
        # T·∫£i m√¥ h√¨nh t·ªët nh·∫•t ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán
        trained_model = YOLO(weights_path)

        # L·∫•y m·ªôt ·∫£nh ng·∫´u nhi√™n t·ª´ t·∫≠p validation ƒë·ªÉ ki·ªÉm tra
        val_image_dir = 'dataset/images/val'
        if os.path.exists(val_image_dir) and len(os.listdir(val_image_dir)) > 0:
            sample_image_name = os.listdir(val_image_dir)[0]
            sample_image_path = os.path.join(val_image_dir, sample_image_name)
            
            print(f"   - Predicting on image: {sample_image_path}")

            # Ch·∫°y nh·∫≠n di·ªán v√† l∆∞u k·∫øt qu·∫£
            results = trained_model.predict(source=sample_image_path, save=True)
            print("   - Prediction complete! Result saved in the latest `runs/detect/predict` folder.")
        else:
            print("   - Could not find any validation images to test.")

    except Exception as e:
        print(f"‚ùå An error occurred during inference: {e}")

if __name__ == '__main__':
    best_weights_path = train_model()
    # B·ªè comment (x√≥a d·∫•u #) ·ªü d√≤ng d∆∞·ªõi ƒë·ªÉ t·ª± ƒë·ªông ch·∫°y inference sau khi train xong.
    # run_inference(best_weights_path)